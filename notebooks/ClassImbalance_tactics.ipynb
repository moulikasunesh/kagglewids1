{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying various tactics for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>pre_icu_los_days</th>\n",
       "      <th>readmission_status</th>\n",
       "      <th>weight</th>\n",
       "      <th>...</th>\n",
       "      <th>icu_type_CCU-CTICU</th>\n",
       "      <th>icu_type_CSICU</th>\n",
       "      <th>icu_type_CTICU</th>\n",
       "      <th>icu_type_Cardiac ICU</th>\n",
       "      <th>icu_type_MICU</th>\n",
       "      <th>icu_type_Med-Surg ICU</th>\n",
       "      <th>icu_type_Neuro ICU</th>\n",
       "      <th>icu_type_SICU</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>66154</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.730000</td>\n",
       "      <td>0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114252</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.927778</td>\n",
       "      <td>0</td>\n",
       "      <td>70.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119783</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.950000</td>\n",
       "      <td>0</td>\n",
       "      <td>172.7</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0</td>\n",
       "      <td>95.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79267</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.640000</td>\n",
       "      <td>1</td>\n",
       "      <td>165.1</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92056</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.844926</td>\n",
       "      <td>0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0.073611</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              hospital_death  hospital_id   age        bmi  elective_surgery  \\\n",
       "encounter_id                                                                   \n",
       "66154                      0          118  68.0  22.730000                 0   \n",
       "114252                     0           81  77.0  27.420000                 0   \n",
       "119783                     0          118  25.0  31.950000                 0   \n",
       "79267                      0          118  81.0  22.640000                 1   \n",
       "92056                      0           33  19.0  14.844926                 0   \n",
       "\n",
       "              height  icu_id  pre_icu_los_days  readmission_status  weight  \\\n",
       "encounter_id                                                                 \n",
       "66154          180.3      92          0.541667                   0    73.9   \n",
       "114252         160.0      90          0.927778                   0    70.2   \n",
       "119783         172.7      93          0.000694                   0    95.3   \n",
       "79267          165.1      92          0.000694                   0    61.7   \n",
       "92056          188.0      91          0.073611                   0    68.0   \n",
       "\n",
       "              ...  icu_type_CCU-CTICU  icu_type_CSICU  icu_type_CTICU  \\\n",
       "encounter_id  ...                                                       \n",
       "66154         ...                   0               0               1   \n",
       "114252        ...                   0               0               0   \n",
       "119783        ...                   0               0               0   \n",
       "79267         ...                   0               0               1   \n",
       "92056         ...                   0               0               0   \n",
       "\n",
       "              icu_type_Cardiac ICU  icu_type_MICU  icu_type_Med-Surg ICU  \\\n",
       "encounter_id                                                               \n",
       "66154                            0              0                      0   \n",
       "114252                           0              0                      1   \n",
       "119783                           0              0                      1   \n",
       "79267                            0              0                      0   \n",
       "92056                            0              0                      1   \n",
       "\n",
       "              icu_type_Neuro ICU  icu_type_SICU  gender_F  gender_M  \n",
       "encounter_id                                                         \n",
       "66154                          0              0         0         1  \n",
       "114252                         0              0         1         0  \n",
       "119783                         0              0         1         0  \n",
       "79267                          0              0         1         0  \n",
       "92056                          0              0         0         1  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_file_path = os.path.join(processed_data_path, 'train1.csv')\n",
    "train_df = pd.read_csv(train_file_path, index_col='encounter_id')\n",
    "# df.head(30)\n",
    "test_file_path = os.path.join(processed_data_path, 'test1.csv')\n",
    "test_df = pd.read_csv(test_file_path, index_col='encounter_id')\n",
    "test_df.shape\n",
    "df = train_df\n",
    "df.head()\n",
    "# test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using upsampling\n",
    "## using down sampling\n",
    "## split train and test\n",
    "## using logistic regression with up and down sampling\n",
    "## change performance metric\n",
    "## support vector Machine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df[df['hospital_death']==0]\n",
    "df_minority = df[df['hospital_death']==1]\n",
    "# df_majority.shape\n",
    "# (83798, 235)\n",
    "# df_minority.shape\n",
    "# (7915, 235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=83798, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    83798\n",
       "0    83798\n",
       "Name: hospital_death, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled['hospital_death'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True cases:  83798 (50.00%)\n",
      "Number of False cases: 83798 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "# verifiying  class is balanced \n",
    "num_obs = len(df_upsampled)\n",
    "num_true = len(df_upsampled.loc[df_upsampled['hospital_death'] == 1])\n",
    "num_false = len(df_upsampled.loc[df_upsampled['hospital_death'] == 0])\n",
    "print(\"Number of True cases:  {0} ({1:2.2f}%)\".format(num_true, (num_true/num_obs) * 100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false/num_obs) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_upsampled.loc[:,'hospital_id':].values.astype('float')\n",
    "y= df_upsampled['hospital_death'].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134076, 234) (134076,)\n",
      "(33520, 234) (33520,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "                            \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original True  : 83798 (50.000%)\n",
      "Original False : 83798 (50.00%)\n",
      "\n",
      "Training True  : 66836 (49.85%)\n",
      "Training False : 67240 (50.15%)\n",
      "\n",
      "Test True      : 16962 (50.60%)\n",
      "Test False     : 16558 (49.40%)\n"
     ]
    }
   ],
   "source": [
    "## after split make sure class ration is main tained\n",
    "\n",
    "print(\"Original True  : {0} ({1:0.3f}%)\".format(len(df_upsampled.loc[df['hospital_death'] == 1]), (len(df_upsampled.loc[df['hospital_death'] == 1])/len(df_upsampled.index)) * 100.0))\n",
    "print(\"Original False : {0} ({1:0.2f}%)\".format(len(df_upsampled.loc[df['hospital_death'] == 0]), (len(df_upsampled.loc[df['hospital_death'] == 0])/len(df_upsampled.index)) * 100.0))\n",
    "print(\"\")\n",
    "print(\"Training True  : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train) * 100.0)))\n",
    "print(\"Training False : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train) * 100.0)))\n",
    "print(\"\")\n",
    "print(\"Test True      : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test) * 100.0)))\n",
    "print(\"Test False     : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test) * 100.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model_lr_2 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m785017/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## peformance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training set\n",
    "pred_y_2 = model_lr_2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression - version 1 : 0.81\n",
      "confusion matrix for logistic regression - version 1: \n",
      " [[13574  2984]\n",
      " [ 3496 13466]]\n",
      "precision for logistic regression - version 1 : 0.82\n",
      "recall for logistic regression - version 1 : 0.79\n",
      "roc score for logistic regression - version 1 : 0.81\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "# accuracy\n",
    "print ('accuracy for logistic regression - version 1 : {0:.2f}'.format(accuracy_score(y_test, model_lr_2.predict(X_test))))\n",
    "# confusion matrix\n",
    "print ('confusion matrix for logistic regression - version 1: \\n {0}'.format(confusion_matrix(y_test, model_lr_2.predict(X_test))))\n",
    "# precision \n",
    "print ('precision for logistic regression - version 1 : {0:.2f}'.format(precision_score(y_test, model_lr_2.predict(X_test))))\n",
    "# precision \n",
    "print ('recall for logistic regression - version 1 : {0:.2f}'.format(recall_score(y_test, model_lr_2.predict(X_test))))\n",
    "# ROC score \n",
    "print ('roc score for logistic regression - version 1 : {0:.2f}'.format(roc_auc_score(y_test, model_lr_2.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    #converting to matrix\n",
    "    test_X = test.values.astype('float')\n",
    "    #make predictions\n",
    "    predictions = model.predict(test_X)\n",
    "    # submission data Frame\n",
    "    df_submission = pd.DataFrame({'encounter_id':test.index, 'hospital_death':predictions})\n",
    "    # submission file\n",
    "    submission_data_path = os.path.join(os.path.pardir, 'data', 'external')\n",
    "    submission_file_path = os.path.join(submission_data_path, filename)\n",
    "    #write to the file\n",
    "    df_submission.to_csv(submission_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(model_lr_2, 'lr_upsampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down sampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df[df['hospital_death']==0]\n",
    "df_minority = df[df['hospital_death']==1]\n",
    "# df_majority.shape\n",
    "# (83798, 235)\n",
    "# df_minority.shape\n",
    "# (7915, 235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority_downsampled = resample(df_majority, replace=True, n_samples=7915, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15830, 235)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled = pd.concat([df_minority, df_majority_downsampled])\n",
    "df_downsampled.shape\n",
    "# (15830, 235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_downsampled.loc[:,'hospital_id':].values.astype('float')\n",
    "y= df_downsampled['hospital_death'].ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12664, 234) (12664,)\n",
      "(3166, 234) (3166,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "                            \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_3 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m785017/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression - version 1 : 0.79\n",
      "confusion matrix for logistic regression - version 1: \n",
      " [[1302  296]\n",
      " [ 359 1209]]\n",
      "precision for logistic regression - version 1 : 0.80\n",
      "recall for logistic regression - version 1 : 0.77\n",
      "roc score for logistic regression - version 1 : 0.79\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "# accuracy\n",
    "print ('accuracy for logistic regression - version 1 : {0:.2f}'.format(accuracy_score(y_test, model_lr_3.predict(X_test))))\n",
    "# confusion matrix\n",
    "print ('confusion matrix for logistic regression - version 1: \\n {0}'.format(confusion_matrix(y_test, model_lr_3.predict(X_test))))\n",
    "# precision \n",
    "print ('precision for logistic regression - version 1 : {0:.2f}'.format(precision_score(y_test, model_lr_3.predict(X_test))))\n",
    "# precision \n",
    "print ('recall for logistic regression - version 1 : {0:.2f}'.format(recall_score(y_test, model_lr_3.predict(X_test))))\n",
    "# ROC score \n",
    "print ('roc score for logistic regression - version 1 : {0:.2f}'.format(roc_auc_score(y_test, model_lr_3.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(model_lr_3, 'lr_downsampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## support vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path, index_col='encounter_id')\n",
    "test_df = pd.read_csv(test_file_path, index_col='encounter_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.loc[:,'hospital_id':].values.astype('float')\n",
    "y= train_df['hospital_death'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1 = SVC(kernel=\"linear\", class_weight=\"balanced\", probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrics\n",
    "# accuracy\n",
    "print ('accuracy for SVM - version 1 : {0:.3f}'.format(accuracy_score(y_test, svm_1.predict(X_test))))\n",
    "# confusion matrix\n",
    "print ('confusion matrix for SVM - version 1: \\n {0}'.format(confusion_matrix(y_test, svm_1.predict(X_test))))\n",
    "# precision \n",
    "print ('precision for SVM - version 1 : {0:.23}'.format(precision_score(y_test, svm_1.predict(X_test))))\n",
    "# precision \n",
    "print ('recall for SVM - version 1 : {0:.3f}'.format(recall_score(y_test, svm_1.predict(X_test))))\n",
    "# ROC score \n",
    "print ('roc score for SVM - version 1 : {0:.3f}'.format(roc_auc_score(y_test, svm_1.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(svm_1, 'svmachine.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
